**_Lecture 11 - Ensembles_**

- Broadly explain the idea of ensembles
- Explain how does predict work in the context of random forest models
- Explain the sources of randomness in random forest algorithm
- Explain the relation between number of estimators and the fundamental tradeoff in the context of random forests
- Use `scikit-learn`'s random forest classification and regression models and explain their main hyperparameters
- Use other tree-based models such as as `XGBoost`, `LGBM` and `CatBoost`
- Broadly explain ensemble approaches, in particular model averaging and stacking.
- Use `scikit-learn` implementations of these ensemble methods.

**_Lecture 12 - Feature Importance_**

- Interpret the coefficients of linear regression for ordinal, one-hot encoded categorical, and scaled numeric features.
- Explain why interpretability is important in ML.
- Use `feature_importances_` attribute of `sklearn` models and interpret its output.
- Apply SHAP to assess feature importances and interpret model predictions.
- Explain force plot, summary plot, and dependence plot produced with shapely values.
